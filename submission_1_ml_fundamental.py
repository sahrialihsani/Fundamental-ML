# -*- coding: utf-8 -*-
"""Submission_1_ML_Fundamental.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pUvaTPRhm3dFHg8QZmpNOWOxBUy5tbup

# Data Diri

Nama : Sahrial Ihsani Ishak

Asal : Bengkulu

# Build LSTM Model
"""

from google.colab import drive
drive.mount('/content/drive')

#Import Library
import pandas as pd #Pandas to process dataset
from sklearn.model_selection import train_test_split #split dataset into training and validation  
from tensorflow.keras.preprocessing.text import Tokenizer #make tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences #make sequences
import tensorflow as tf #tensorflow

#read dataset
dataset = pd.read_csv('/content/drive/MyDrive/news.csv')
display(dataset.head())

#drop category and split category
kategori_berita = pd.get_dummies(dataset.category)
dataset_baru = pd.concat([dataset, kategori_berita], axis=1)
dataset_baru = dataset_baru.drop(columns='category')
dataset_baru

#preparing text and label
teks = dataset_baru['text'].values
label = dataset_baru[['business', 'entertainment', 'politics', 'sport', 'tech']].values

#Divide the dataset into train and validation
teks_latih, teks_test, label_latih, label_test = train_test_split(teks, label, test_size=0.2)

#create tokenizer and padding
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(teks_latih) 
tokenizer.fit_on_texts(teks_test)
word_index = tokenizer.word_index
sekuens_latih = tokenizer.texts_to_sequences(teks_latih)
sekuens_test = tokenizer.texts_to_sequences(teks_test)
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

#Callback to avoid overfitting
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.95):
      print("\nAkurasi telah lebih dari 95%!")
      self.model.stop_training = True
callbacks = myCallback()

#create model
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=64),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

plot_model = model.fit(padded_latih, label_latih, epochs=30, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt
#Accuracy  
plt.plot(plot_model.history['accuracy'])
plt.plot(plot_model.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
#Loss
plt.plot(plot_model.history['loss'])
plt.plot(plot_model.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()